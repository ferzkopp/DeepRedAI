{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbc9a76",
   "metadata": {},
   "source": [
    "# Test Local Opensearch\n",
    "\n",
    "Notebook that tests the local Opensearch vector database of Wikipedia content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65666334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "# Server configuration\n",
    "HOST = \"192.168.X.Y\"  # Replace with your server's IP address\n",
    "OPENSEARCH_URL = f\"http://{HOST}:9200\"\n",
    "LM_STUDIO_URL = f\"http://{HOST}:1234\"\n",
    "EMBEDDING_MODEL = \"text-embedding-nomic-embed-text-v1.5@f16\"\n",
    "\n",
    "# Wikipedia index name (from process_and_index.py)\n",
    "INDEX_NAME = \"wikipedia\"\n",
    "\n",
    "print(f\"OpenSearch URL: {OPENSEARCH_URL}\")\n",
    "print(f\"LM Studio URL: {LM_STUDIO_URL}\")\n",
    "print(f\"Index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439db78",
   "metadata": {},
   "source": [
    "## 1. Test OpenSearch Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick connectivity diagnostics\n",
    "import socket\n",
    "\n",
    "def check_port(host: str, port: int, timeout: float = 5.0) -> bool:\n",
    "    \"\"\"Check if a port is reachable.\"\"\"\n",
    "    try:\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        sock.settimeout(timeout)\n",
    "        result = sock.connect_ex((host, port))\n",
    "        sock.close()\n",
    "        return result == 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "host = HOST\n",
    "ports = {\n",
    "    22: \"SSH\",\n",
    "    1234: \"LM Studio\",\n",
    "    9200: \"OpenSearch\"\n",
    "}\n",
    "\n",
    "print(f\"Checking connectivity to {host}...\")\n",
    "print(\"-\" * 40)\n",
    "for port, service in ports.items():\n",
    "    status = \"✓ Open\" if check_port(host, port) else \"✗ Closed/Blocked\"\n",
    "    print(f\"  Port {port:5} ({service:12}): {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"If OpenSearch port 9200 is blocked, run on server:\")\n",
    "print(f\"  sudo ufw allow from {HOST}/24 to any port 9200 proto tcp\")\n",
    "print(\"\\nIf OpenSearch is not running:\")\n",
    "print(\"  sudo systemctl status opensearch\")\n",
    "print(\"  sudo systemctl start opensearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce303a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenSearch cluster health\n",
    "try:\n",
    "    response = requests.get(f\"{OPENSEARCH_URL}/_cluster/health\", timeout=10)\n",
    "    response.raise_for_status()\n",
    "    health = response.json()\n",
    "    print(\"✓ OpenSearch cluster is reachable!\")\n",
    "    print(f\"  Cluster: {health['cluster_name']}\")\n",
    "    print(f\"  Status: {health['status']}\")\n",
    "    print(f\"  Nodes: {health['number_of_nodes']}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"✗ Failed to connect to OpenSearch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49930696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Wikipedia index\n",
    "try:\n",
    "    response = requests.get(f\"{OPENSEARCH_URL}/{INDEX_NAME}/_count\", timeout=10)\n",
    "    response.raise_for_status()\n",
    "    count_data = response.json()\n",
    "    print(f\"✓ Index '{INDEX_NAME}' exists!\")\n",
    "    print(f\"  Document count: {count_data['count']:,}\")\n",
    "    \n",
    "    # Get index mapping to verify embedding field\n",
    "    mapping_resp = requests.get(f\"{OPENSEARCH_URL}/{INDEX_NAME}/_mapping\", timeout=10)\n",
    "    mapping = mapping_resp.json()\n",
    "    props = mapping[INDEX_NAME]['mappings'].get('properties', {})\n",
    "    if 'embedding' in props:\n",
    "        emb_info = props['embedding']\n",
    "        print(f\"  Embedding field: {emb_info.get('type', 'unknown')}\")\n",
    "        print(f\"  Dimension: {emb_info.get('dimension', 'unknown')}\")\n",
    "    else:\n",
    "        print(\"  Warning: No 'embedding' field found in mapping\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"✗ Failed to access index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945f01a",
   "metadata": {},
   "source": [
    "## 2. Embedding Client (from testEmbedding.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EmbeddingResult:\n",
    "    \"\"\"Result of an embedding operation.\"\"\"\n",
    "    text: str\n",
    "    embedding: List[float]\n",
    "    index: int\n",
    "    \n",
    "    @property\n",
    "    def vector(self) -> np.ndarray:\n",
    "        \"\"\"Return embedding as numpy array.\"\"\"\n",
    "        return np.array(self.embedding, dtype=np.float32)\n",
    "\n",
    "\n",
    "class EmbeddingClient:\n",
    "    \"\"\"\n",
    "    Client for generating text embeddings using LM Studio's API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        base_url: str = LM_STUDIO_URL,\n",
    "        model: str = EMBEDDING_MODEL,\n",
    "        timeout: int = 60\n",
    "    ):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.model = model\n",
    "        self.timeout = timeout\n",
    "        self._dimension: Optional[int] = None\n",
    "    \n",
    "    @property\n",
    "    def dimension(self) -> int:\n",
    "        \"\"\"Get the embedding dimension (lazy-loaded).\"\"\"\n",
    "        if self._dimension is None:\n",
    "            result = self.embed(\"test\")\n",
    "            self._dimension = len(result)\n",
    "        return self._dimension\n",
    "    \n",
    "    def embed(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Embed a single text string.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to embed\n",
    "            \n",
    "        Returns:\n",
    "            Embedding vector as list of floats\n",
    "        \"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/v1/embeddings\",\n",
    "            json={\"model\": self.model, \"input\": [text]},\n",
    "            timeout=self.timeout\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "# Test the embedding client\n",
    "try:\n",
    "    client = EmbeddingClient()\n",
    "    test_embedding = client.embed(\"test connection\")\n",
    "    print(f\"✓ Embedding client working!\")\n",
    "    print(f\"  Model: {client.model}\")\n",
    "    print(f\"  Dimension: {len(test_embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Embedding client error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f3cef",
   "metadata": {},
   "source": [
    "## 3. Semantic Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9181c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(\n",
    "    query_text: str, \n",
    "    client: EmbeddingClient,\n",
    "    top_k: int = 3,\n",
    "    index_name: str = INDEX_NAME\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Perform semantic search using k-NN on OpenSearch.\n",
    "    \n",
    "    Args:\n",
    "        query_text: The search query text\n",
    "        client: EmbeddingClient instance\n",
    "        top_k: Number of results to return\n",
    "        index_name: OpenSearch index name\n",
    "        \n",
    "    Returns:\n",
    "        List of matching documents with scores\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = client.embed(query_text)\n",
    "    \n",
    "    # Build k-NN search query\n",
    "    search_query = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"embedding\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"k\": top_k\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"title\", \"section_title\", \"text\", \"url\"]\n",
    "    }\n",
    "    \n",
    "    # Execute search\n",
    "    response = requests.post(\n",
    "        f\"{OPENSEARCH_URL}/{index_name}/_search\",\n",
    "        json=search_query,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=30\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse results\n",
    "    results = []\n",
    "    hits = response.json().get(\"hits\", {}).get(\"hits\", [])\n",
    "    for hit in hits:\n",
    "        source = hit.get(\"_source\", {})\n",
    "        results.append({\n",
    "            \"score\": hit.get(\"_score\", 0),\n",
    "            \"title\": source.get(\"title\", \"Unknown\"),\n",
    "            \"section\": source.get(\"section_title\", \"\"),\n",
    "            \"text\": source.get(\"text\", \"\")[:500],  # Truncate for display\n",
    "            \"url\": source.get(\"url\", \"\")\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(results: List[dict], query: str):\n",
    "    \"\"\"Pretty print search results.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n--- Result {i} (Score: {result['score']:.4f}) ---\")\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        if result['section']:\n",
    "            print(f\"Section: {result['section']}\")\n",
    "        print(f\"\\nText preview:\")\n",
    "        print(f\"{result['text']}...\")\n",
    "        if result['url']:\n",
    "            print(f\"\\nURL: {result['url']}\")\n",
    "\n",
    "\n",
    "print(\"✓ Search functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83995ca7",
   "metadata": {},
   "source": [
    "## 4. Run Sample Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample search query - modify this to test different queries\n",
    "SAMPLE_QUERY = \"art history in Germany and the Bauhaus movement\"\n",
    "\n",
    "# Perform the search\n",
    "try:\n",
    "    print(f\"Searching for: '{SAMPLE_QUERY}'\")\n",
    "    print(\"Generating embedding...\")\n",
    "    \n",
    "    results = semantic_search(SAMPLE_QUERY, client, top_k=3)\n",
    "    display_results(results, SAMPLE_QUERY)\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"✗ Search failed: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93377c",
   "metadata": {},
   "source": [
    "## 5. Interactive Search (Optional)\n",
    "\n",
    "Run the cell below to try different search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different queries here\n",
    "queries = [\n",
    "    \"quantum mechanics and wave particle duality\",\n",
    "    \"French Revolution causes and effects\",\n",
    "    \"machine learning neural networks\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    try:\n",
    "        results = semantic_search(query, client, top_k=3)\n",
    "        display_results(results, query)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Query '{query}' failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
